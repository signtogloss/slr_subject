import React, { useState, useEffect, useRef } from 'react';
import '../modern-styles.css';

// Ê£ÄÊü•ÊµèËßàÂô®ÊòØÂê¶ÊîØÊåÅËØ≠Èü≥ÂêàÊàêAPI
const speechSynthesisSupported = 'speechSynthesis' in window;

const SignLanguageRecognition = () => {
  const [isRecording, setIsRecording] = useState(false);
  const [recognitions, setRecognitions] = useState([]);
  const [error, setError] = useState('');
  const [isSpeaking, setIsSpeaking] = useState(false);
  
  const videoRef = useRef(null);
  const mediaRecorderRef = useRef(null);
  const websocketRef = useRef(null);
  const streamRef = useRef(null);

  // ÂΩìËØÜÂà´ÁªìÊûúÊõ¥Êñ∞Êó∂ÔºåÊúóËØªÊúÄÊñ∞ÁöÑÁªìÊûú
  useEffect(() => {
    if (recognitions.length > 0 && speechSynthesisSupported) {
      // Ëé∑ÂèñÊúÄÊñ∞ÁöÑËØÜÂà´ÁªìÊûú
      const latestRecognition = recognitions[recognitions.length - 1];
      let textToSpeak = '';
      
      // Ê†πÊçÆÁªìÊûúÁ±ªÂûãÊèêÂèñÊñáÊú¨
      if (typeof latestRecognition === 'object') {
        textToSpeak = latestRecognition.prediction || latestRecognition.text || 'Êú™Áü•';
      } else {
        textToSpeak = latestRecognition;
      }
      
      // ÂàõÂª∫ËØ≠Èü≥ÂêàÊàêÂÆû‰æã
      const utterance = new SpeechSynthesisUtterance(textToSpeak);
      
      // ËÆæÁΩÆËØ≠Èü≥Â±ûÊÄßÔºàÂèØÈÄâÔºâ
      utterance.lang = 'zh-CN'; // ËÆæÁΩÆËØ≠Ë®Ä‰∏∫‰∏≠Êñá
      utterance.rate = 1.0;     // ËØ≠ÈÄü (0.1 Âà∞ 10)
      utterance.pitch = 1.0;    // Èü≥Ë∞É (0 Âà∞ 2)
      utterance.volume = 1.0;   // Èü≥Èáè (0 Âà∞ 1)
      
      // ËØ≠Èü≥ÂºÄÂßãÂíåÁªìÊùü‰∫ã‰ª∂Â§ÑÁêÜ
      utterance.onstart = () => setIsSpeaking(true);
      utterance.onend = () => setIsSpeaking(false);
      utterance.onerror = (event) => {
        console.error('ËØ≠Èü≥ÂêàÊàêÈîôËØØ:', event);
        setIsSpeaking(false);
      };
      
      // ÂºÄÂßãÊúóËØª
      window.speechSynthesis.speak(utterance);
    }
  }, [recognitions]);
  
  // ÁªÑ‰ª∂ÊåÇËΩΩÊó∂ÂàùÂßãÂåñÊëÑÂÉèÂ§¥ÂíåMediaRecorder
  useEffect(() => {
    async function initMedia() {
      try {
        // Ëé∑ÂèñËßÜÈ¢ëÊµÅ
        const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: false });
        streamRef.current = stream;
        if (videoRef.current) {
          videoRef.current.srcObject = stream;
        }
        console.log('Video stream initialized successfully');

        // Ëá™Âä®ÈÄâÊã©ÊîØÊåÅÁöÑ MIME Á±ªÂûã
        let mimeType = '';
        if (MediaRecorder.isTypeSupported('video/webm;codecs=vp9')) {
          mimeType = 'video/webm;codecs=vp9';
        } else if (MediaRecorder.isTypeSupported('video/webm')) {
          mimeType = 'video/webm';
        } else if (MediaRecorder.isTypeSupported('video/mp4')) {
          mimeType = 'video/mp4';
        } else {
          throw new Error('Current browser does not support suitable video encoding format');
        }
        const options = { bitsPerSecond: 1000000, mimeType };
        mediaRecorderRef.current = new MediaRecorder(stream, options);
        console.log('MediaRecorder initialized successfully, using MIME type:', mediaRecorderRef.current.mimeType);
      } catch (err) {
        const msg = `Camera initialization failed: ${err.message}`;
        setError(msg);
        console.error(msg);
      }
    }
    initMedia();

    // ÁªÑ‰ª∂Âç∏ËΩΩÊó∂Ê∏ÖÁêÜËµÑÊ∫ê
    return () => {
      if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
        mediaRecorderRef.current.stop();
      }
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
      }
      if (websocketRef.current && websocketRef.current.readyState === WebSocket.OPEN) {
        websocketRef.current.close();
      }
      // ÂèñÊ∂àÊâÄÊúâÊ≠£Âú®ËøõË°åÁöÑËØ≠Èü≥ÂêàÊàê
      if (speechSynthesisSupported) {
        window.speechSynthesis.cancel();
      }
    };
  }, []);

  // ÂêØÂä®ËØÜÂà´ÈÄªËæë
  const startRecognition = async () => {
    setError('');

    // Âª∫Á´ã WebSocket ËøûÊé•
    // const ws = new WebSocket('wss://api.sign-speak.com/stream-recognize-sign');
    const ws = new WebSocket('wss://api.signbridgeai.com/recognize_sign_ws');

    websocketRef.current = ws;

    // ËøûÊé•ÊâìÂºÄÊó∂ÂêØÂä®ÂΩïÂà∂
    ws.addEventListener('open', () => {
      console.log('WebSocket connection opened');

      // ÂΩìÂΩïÂà∂Âà∞‰∏ÄÊÆµËßÜÈ¢ëÊï∞ÊçÆÊó∂ÔºåË∞ÉÁî® ondataavailable ÂõûË∞ÉÂèëÈÄÅÊï∞ÊçÆÂà∞ÊúçÂä°Âô®
      mediaRecorderRef.current.ondataavailable = (event) => {
        console.log('Captured ondataavailable event, data size:', event.data.size, 'bytes');
        // ‰ΩøÁî® MediaRecorder ÁöÑ MIME Á±ªÂûãÊûÑÈÄ† Blob
        const blob = new Blob([event.data], { type: mediaRecorderRef.current.mimeType });
        const reader = new FileReader();
        reader.onloadend = () => {
          const buffer = reader.result;
          console.log('Sending video data chunk, size:', buffer.byteLength);
          if (ws.readyState === WebSocket.OPEN) {
            ws.send(buffer);
          } else {
            console.warn('Failed to send video data, WebSocket state is not OPEN:', ws.readyState);
          }
        };
        reader.readAsArrayBuffer(blob);
      };

      // ÂºÄÂßãÂΩïÂà∂Ôºå‰º†ÂÖ•ÁöÑÊó∂Èó¥Èó¥ÈöîÂøÖÈ°ª‰∏é slice_length ÈÖçÁΩÆ‰∏ÄËá¥
      mediaRecorderRef.current.start(500);
      setIsRecording(true);
      console.log('MediaRecorder ÂºÄÂßãÂΩïÂà∂ÔºåÂàáÁâáÈó¥Èöî 500ms');
    });

    // ÁõëÂê¨ WebSocket Ê∂àÊÅØÔºåÂ§ÑÁêÜÊúçÂä°Âô®ËøîÂõûÁöÑÊï∞ÊçÆ
    ws.addEventListener('message', (event) => {
      console.log('Êé•Êî∂Âà∞ WebSocket Ê∂àÊÅØ:', event.data);
      try {
        // Â∞ùËØïËß£ÊûêÊúçÂä°Âô®ËøîÂõûÁöÑ JSON Êï∞ÊçÆ
        const data = JSON.parse(event.data);
        // ÁßªÈô§APIÈÖçÈ¢ùÊ£ÄÊü•ÔºåÂõ†‰∏∫‰∏çÂÜçÈúÄË¶ÅAPI token
        // Â¶ÇÊûúÈúÄË¶ÅÂÖ∂‰ªñÈîôËØØÊ£ÄÊü•ÔºåÂèØ‰ª•Âú®ËøôÈáåÊ∑ªÂä†
        // Ê†πÊçÆËøîÂõûÊï∞ÊçÆÁªìÊûÑÊèêÂèñËØÜÂà´ÁªìÊûúÂ≠óÊÆµÔºö prediction Êàñ predictions Êàñ results
        const predictions = data.prediction || data.predictions || data.results;
        if (!predictions) {
          console.warn('No recognition result field found in returned data:', data);
          return;
        }
        console.log('Parsed recognition results:', predictions);
        // Êõ¥Êñ∞ËØÜÂà´ÁªìÊûúÂàóË°®
        setRecognitions(prev => [...prev, ...predictions]);
      } catch (err) {
        console.error('Failed to parse returned data:', err, event.data);
      }
    });

    ws.addEventListener('error', (err) => {
      console.error('WebSocket error occurred:', err);
      setError('WebSocket connection error');
    });

    ws.addEventListener('close', (event) => {
      console.log('WebSocket connection closed, status code:', event.code, 'reason:', event.reason);
      setIsRecording(false);
    });
  };

  // ÂÅúÊ≠¢ËØÜÂà´Âπ∂ÂÖ≥Èó≠ËøûÊé•
  const stopRecognition = () => {
    console.log('Triggering stop recognition operation');
    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
      mediaRecorderRef.current.stop();
      console.log('MediaRecorder has stopped recording');
    }
    if (websocketRef.current && websocketRef.current.readyState === WebSocket.OPEN) {
      websocketRef.current.send('DONE');
      console.log('Sent DONE signal');
      // websocketRef.current.close();  this is the point, we should not use it.
    }
    setIsRecording(false);
    
    // ÂÅúÊ≠¢ÂΩìÂâçÊ≠£Âú®ËøõË°åÁöÑËØ≠Èü≥ÂêàÊàê
    if (speechSynthesisSupported && isSpeaking) {
      window.speechSynthesis.cancel();
      setIsSpeaking(false);
    }
  };

  return (
    <div className="row">
      <div className="col-lg-7 mb-4 mb-lg-0">
        {/* Video container */}
        <div className="video-container mb-3">
          <video
            ref={videoRef}
            autoPlay
            playsInline
            muted
          ></video>
        </div>
        
        <div className="d-flex justify-content-center mb-3">
          <button 
            className={`btn ${isRecording ? 'btn-secondary' : 'btn-primary'} px-4 py-2`}
            onClick={isRecording ? stopRecognition : startRecognition}
          >
            {isRecording ? 'Stop Recognition' : 'Start Recognition'}
          </button>
        </div>
        
        {error && (
          <div className="alert alert-danger fade-in" role="alert">
            <i className="fas fa-exclamation-circle me-2"></i>
            Error: {error}
          </div>
        )}
      </div>
      
      <div className="col-lg-5">
        <div className="card">
          <div className="card-header bg-secondary d-flex justify-content-between align-items-center">
            <h3 className="mb-0 fs-5">Recognition Results</h3>
            {isSpeaking && (
              <span className="badge bg-info">
                <i className="bi bi-volume-up me-1"></i> Speaking
              </span>
            )}
            {!speechSynthesisSupported && (
              <span className="badge bg-warning">
                <i className="bi bi-exclamation-triangle me-1"></i> Speech not supported
              </span>
            )}
          </div>
          <div className="card-body" style={{maxHeight: '400px', overflowY: 'auto'}}>
            {recognitions.length > 0 ? (
              <div className="recognition-results">
                {recognitions.map((pred, idx) => {
                  // Support for returned objects (containing prediction, confidence, finished, etc.) or strings
                  if (typeof pred === 'object') {
                    const confidence = Math.round((pred.confidence || 1) * 100);
                    return (
                      <div key={idx} className="recognition-item slide-up" style={{animationDelay: `${idx * 0.05}s`}}>
                        <div className="d-flex justify-content-between align-items-center mb-1">
                          <strong className="fs-5">{pred.prediction || pred.text || 'Unknown'}</strong>
                          <span className="badge bg-primary">Confidence: {confidence}%</span>
                        </div>
                        <div className="progress mb-3" style={{height: '6px'}}>
                          <div 
                            className="progress-bar" 
                            role="progressbar" 
                            style={{width: `${confidence}%`, background: 'var(--primary-gradient)'}} 
                            aria-valuenow={confidence} 
                            aria-valuemin="0" 
                            aria-valuemax="100"
                          ></div>
                        </div>
                        {pred.finished && (
                          <span className="badge bg-success mb-2">Completed</span>
                        )}
                        <hr className="my-2" />
                      </div>
                    );
                  } else {
                    return (
                      <div key={idx} className="recognition-item slide-up" style={{animationDelay: `${idx * 0.05}s`}}>
                        <div className="d-flex justify-content-between align-items-center mb-2">
                          <span>{pred}</span>
                        </div>
                        <hr className="my-2" />
                      </div>
                    );
                  }
                })}
              </div>
            ) : (
              <div className="text-center py-4 text-muted">
                <div className="mb-3 fs-3">üìù</div>
                <p>No recognition results yet...</p>
                <p className="small">Click "Start Recognition" button to begin sign language recognition</p>
              </div>
            )}
          </div>
        </div>
      </div>
    </div>
  );
};

export default SignLanguageRecognition;
